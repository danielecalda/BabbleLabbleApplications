{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_FILE3 = 'data/pos_adjectives_list.pkl'\n",
    "DATA_FILE4 = 'data/neu_adjectives_list.pkl'\n",
    "DATA_FILE5 = 'data/neg_adjectives_list.pkl'\n",
    "\n",
    "DATA_FILE = 'data/data.pkl'\n",
    "with open(DATA_FILE, 'rb') as f:\n",
    "    Cs = pickle.load(f)\n",
    "    \n",
    "DATA_FILE2 = 'data/labels.pkl'  \n",
    "with open(DATA_FILE2, 'rb') as f:\n",
    "    Ys = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityMention(doc_id=1: 'bill'(6:10)\n"
     ]
    }
   ],
   "source": [
    "print(Cs[0][0].entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neu_adjectives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "collections.Counter(Ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Size: {len(Cs[0])}\")\n",
    "print(f\"Dev Size:   {len(Cs[1])}\")\n",
    "print(f\"Test Size:  {len(Cs[2])}\")\n",
    "print(f\"Train Size: {len(Ys[0])}\")\n",
    "print(f\"Dev Size:   {len(Ys[1])}\")\n",
    "print(f\"Test Size:  {len(Ys[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 377 explanations from data/my_explanations.tsv\n"
     ]
    }
   ],
   "source": [
    "from babble.utils import ExplanationIO2\n",
    "\n",
    "FILE = \"data/my_explanations.tsv\"\n",
    "exp_io = ExplanationIO2()\n",
    "explanations = exp_io.read(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word \"total\" is within 2 words of \"bill\"\n"
     ]
    }
   ],
   "source": [
    "print(explanations[0].condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar construction complete.\n"
     ]
    }
   ],
   "source": [
    "from babble import Babbler\n",
    "babbler = Babbler(Cs, Ys,apply_filters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babbler.add_aliases({'positive': pos_adjectives_list})\n",
    "babbler.add_aliases({'negative': neg_adjectives_list})\n",
    "babbler.add_aliases({'neutral': neu_adjectives_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 0 unique target candidate ids from 377 explanations.\n",
      "No candidate hashes were provided. Skipping linking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |         #                                       | 376 Elapsed Time: 0:00:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377 explanation(s) out of 377 were parseable.\n",
      "377 parse(s) generated from 377 explanation(s).\n",
      "Because apply_filters=False, no parses are being filtered.\n",
      "Applying labeling functions to investigate labeling signature.\n",
      "[========================================] 100%\n",
      "\n",
      "Added 377 parse(s) from 377 explanations to set. (Total # parses = 377)\n",
      "\n",
      "Applying labeling functions to split 1\n",
      "[========================================] 100%\n",
      "\n",
      "Added 0 labels to split 1: L.nnz = 0, L.shape = (812, 377).\n",
      "Applying labeling functions to split 2\n",
      "[========================================] 100%\n",
      "\n",
      "Added 0 labels to split 2: L.nnz = 0, L.shape = (812, 377).\n"
     ]
    }
   ],
   "source": [
    "babbler.apply(explanations, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'nnz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8078190db238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbabbler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mLs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/babbler.py\u001b[0m in \u001b[0;36mget_label_matrix\u001b[0;34m(self, split)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             print(f\"Retrieved label matrix for split {split}: L.nnz = {L.nnz}, \"\n\u001b[0m\u001b[1;32m    351\u001b[0m                 f\"L.shape = {L.shape}\")\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'nnz'"
     ]
    }
   ],
   "source": [
    "Ls = []\n",
    "for split in [0,1,2]:\n",
    "    L = babbler.get_label_matrix(split)\n",
    "    Ls.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(translate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'bill')), ('.string', 'total'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'service')), ('.string', 'horrible'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'place')), ('.string', 'awful'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'staff')), ('.string', 'awful'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'freezer')), ('.string', 'disappointed'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'cream')), ('.string', 'strawberry'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'hour')), ('.string', 'happy'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'food')), ('.string', 'great'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'place')), ('.string', 'worse'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'meal')), ('.string', 'unsatisfactory'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'chipotle')), ('.string', 'regular'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'california')), ('.string', 'chipotle'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'visit')), ('.string', 'first'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'service')), ('.string', 'worst'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'luck')), ('.string', 'good'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'nachos')), ('.string', 'nasty'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'water')), ('.string', 'regular'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'customer')), ('.string', 'terrible'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'service')), ('.string', 'terrible'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'food')), ('.string', 'average'))))\n"
     ]
    }
   ],
   "source": [
    "semantics = [parse.semantics for parse in parses ]\n",
    "for semantic in semantics:\n",
    "    print(semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(parses[0].function(\"bill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses[1].function(Cs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses[2].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal import LabelModel\n",
    "\n",
    "label_aggregator = LabelModel(5)\n",
    "label_aggregator.train(Ls[0], n_epochs=100, lr=0.01)\n",
    "label_aggregator.score(Ls[1], Ys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_p = label_aggregator.predict(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Ls.pkl\", 'wb') as f:\n",
    "    pickle.dump(Ls, f)\n",
    "    \n",
    "with open(\"Y_p.pkl\", 'wb') as f:\n",
    "    pickle.dump(Y_p, f)\n",
    "    \n",
    "with open(\"data/wrong_indexes.pkl\", 'wb') as f:\n",
    "    pickle.dump(wrong_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.PipelineReviewPos.result_analysis import analyze\n",
    "\n",
    "analyze(Ls,parses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:babble] *",
   "language": "python",
   "name": "conda-env-babble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
