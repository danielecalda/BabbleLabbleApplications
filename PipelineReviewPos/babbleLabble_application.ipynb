{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_FILE3 = 'data/pos_adjectives_list.pkl'\n",
    "DATA_FILE4 = 'data/neu_adjectives_list.pkl'\n",
    "DATA_FILE5 = 'data/neg_adjectives_list.pkl'\n",
    "\n",
    "DATA_FILE = 'data/data.pkl'\n",
    "with open(DATA_FILE, 'rb') as f:\n",
    "    Cs = pickle.load(f)\n",
    "    \n",
    "DATA_FILE2 = 'data/labels.pkl'  \n",
    "with open(DATA_FILE2, 'rb') as f:\n",
    "    Ys = pickle.load(f)\n",
    "    \n",
    "with open(DATA_FILE3, 'rb') as f:\n",
    "    pos_adjectives_list = pickle.load(f)\n",
    "    \n",
    "with open(DATA_FILE4, 'rb') as f:\n",
    "    neu_adjectives_list = pickle.load(f)\n",
    "\n",
    "with open(DATA_FILE5, 'rb') as f:\n",
    "    neg_adjectives_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total', 'not', 'strawberry', 'filthy', 'less', 'unsatisfactory', 'first', 'new', 'so', 'regular', 'average', 'be', 'full', 'stodgy', 'different', 'slow', 'mostly', 'only', 'fast', 'unable', 'large', 'slowest', 'online', 'such', 'next', 'early', 'really', 'nt', 'last', 'entire', 'aerobic', 'young', 'the', 'its', 'mediocre', 'plain', 'loud', 'small', 'other', 'late', 'bearded', 'ice', 'second', 'busy', 'was', 'doable', 'iced', 'at', 'dry', 'old', 'decent', 'expensive', 'big', 'very', 'little', 'tasteless', 'few', 'unbearable', 'quick', 'a', 'newer', 'euro', 'national', 'crowded', 'above', 'vulgar', 'apolegetic', 'sweetlike', 'accurate', 'hot', 'bare', 'pretentious', 'raw', 'in', 'galbi', 'much', 'smaller', 'closed', 'grey', 'single', 'main', 'avondale', 'inexperienced', 'soooooo', 'classic', 'gotten', 'quite', 'slower', 'calgary', 'willing', 'local', 'same', 'chinese', 'waitress', 'just', 'available', 'oatmeal', 'an', 'eclectic', 'way', 'high', 'unique', 'bigger', 'goodsandwich', 'too', 'on', 'malaysian', 'extremely', 'long', 'eggplant', 'moderate', 'usual', 'fetalicious', 'residential', 'sour', 'out', 'intimate', 'real', 'huuuge', 'subpar', 'contemporary', 'cold', 'saffron', 'corporate', 'tasty', 'flavourful', 'vietnamese', 'native', 'overall', 'familiar', 'fairly', 'quiet', 'authentic', 'addictive', 'soft', 'french', 'heavy', 'polite', 'more', 'reasonable', 'east', 'knowledgable', 'actually', 'usually', 'clasic', 'quickly', 'mini', 'live', 'annual', 'and', 'unreal', 'latest', 'loco', 'professional', 'aged', 'third', 'my', 'alway', 'with', 'incredible', 'prime', 'identical', 'front', 'knowledgeable', 'mexican', 'sicilian', 'paila', 'key', 'columbian', 'phenomenal', 'black']\n"
     ]
    }
   ],
   "source": [
    "print(neu_adjectives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 177, 2: 171, 3: 176, 4: 177, 5: 169})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "collections.Counter(Ys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 870\n",
      "Dev Size:   825\n",
      "Test Size:  825\n",
      "Train Size: 870\n",
      "Dev Size:   825\n",
      "Test Size:  826\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Size: {len(Cs[0])}\")\n",
    "print(f\"Dev Size:   {len(Cs[1])}\")\n",
    "print(f\"Test Size:  {len(Cs[2])}\")\n",
    "print(f\"Train Size: {len(Ys[0])}\")\n",
    "print(f\"Dev Size:   {len(Ys[1])}\")\n",
    "print(f\"Test Size:  {len(Ys[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 595 explanations from data/my_explanations.tsv\n"
     ]
    }
   ],
   "source": [
    "from babble.utils import ExplanationIO\n",
    "\n",
    "FILE = \"data/my_explanations.tsv\"\n",
    "exp_io = ExplanationIO()\n",
    "explanations = exp_io.read(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explanations[0].candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar construction complete.\n"
     ]
    }
   ],
   "source": [
    "from babble import Babbler\n",
    "babbler = Babbler(Cs, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar construction complete.\n",
      "Grammar construction complete.\n",
      "Grammar construction complete.\n"
     ]
    }
   ],
   "source": [
    "babbler.add_aliases({'positive': pos_adjectives_list})\n",
    "babbler.add_aliases({'negative': neg_adjectives_list})\n",
    "babbler.add_aliases({'neutral': neu_adjectives_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "/ |#                                                  | 0 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 595 unique target candidate ids from 595 explanations.\n",
      "Gathering desired candidates...\n",
      "Could not find 595 target candidates with the following mention_ids (first 5):\n",
      "-7137499708666345355\n",
      "2054342241921923125\n",
      "4248607722652347526\n",
      "-6944025897051368090\n",
      "1893822064894711740\n",
      "Found 0/595 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 0/595 explanations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                                          #      | 594 Elapsed Time: 0:09:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595 explanation(s) out of 595 were parseable.\n",
      "4102 parse(s) generated from 595 explanation(s).\n",
      "1988 parse(s) remain (2114 parse(s) removed by DuplicateSemanticsFilter).\n",
      "Note: 1988 LFs did not have candidates and therefore could not be filtered.\n",
      "1988 parse(s) remain (0 parse(s) removed by ConsistencyFilter).\n",
      "Applying labeling functions to investigate labeling signature.\n",
      "[===========================             ] 65%"
     ]
    }
   ],
   "source": [
    "babbler.apply(explanations, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls = []\n",
    "for split in [0,1,2]:\n",
    "    L = babbler.get_label_matrix(split)\n",
    "    Ls.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(translate=False)\n",
    "print(len(parses))\n",
    "for parse in parses:\n",
    "    babbler.view_parse(parse)\n",
    "    print(parse.function(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal import LabelModel\n",
    "\n",
    "label_aggregator = LabelModel(5)\n",
    "label_aggregator.train(Ls[0], n_epochs=100, lr=0.01)\n",
    "label_aggregator.score(Ls[1], Ys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_p = label_aggregator.predict(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_wrong_train = 0\n",
    "for right, wrong in zip(Ys[0], Y_p):\n",
    "    if right != wrong:\n",
    "        len_wrong_train += 1\n",
    "print(len_wrong_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(line):\n",
    "    filtered_list = list(filter(lambda a: a != 0, line))\n",
    "    if len(filtered_list) > 0:\n",
    "        occurence_count = Counter(filtered_list)\n",
    "        return occurence_count.most_common(1)[0][0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def percentage(part, whole):\n",
    "    return 100 * float(part)/float(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "L_train = Ls[0].toarray()\n",
    "L_test = Ls[2].toarray()\n",
    "\n",
    "predicted_training_labels = []\n",
    "predicted_test_labels = []\n",
    "\n",
    "for line in L_train:\n",
    "    predicted_training_labels.append(most_frequent(line))\n",
    "\n",
    "print(predicted_training_labels)\n",
    "\n",
    "for line in L_test:\n",
    "    predicted_test_labels.append(most_frequent(line))\n",
    "    \n",
    "print(predicted_test_labels)\n",
    "\n",
    "perturbations = []\n",
    "\n",
    "len_wrong_train = 0\n",
    "for right, wrong in zip(Ys[0], predicted_training_labels):\n",
    "    if int(right) != wrong:\n",
    "        len_wrong_train += 1\n",
    "    perturbations.append(int(right) - wrong)\n",
    "\n",
    "perturbations = [abs(perturbation) for perturbation in perturbations]\n",
    "\n",
    "len_wrong_test = 0\n",
    "for right, wrong in zip(Ys[2], predicted_test_labels):\n",
    "    if right != wrong:\n",
    "        len_wrong_test += 1\n",
    "\n",
    "training_accuracy = percentage(len(Ys[0]) -len_wrong_train,len(Ys[0]))\n",
    "test_accuracy = percentage(len(Ys[2]) - len_wrong_test, len(Ys[2]))\n",
    "\n",
    "print(\"Number of wrong in training set: \" + str(len_wrong_train))\n",
    "print(\"Number of wrong in test set: \" + str(len_wrong_test))\n",
    "print(\"Training Accuracy: \" + str(training_accuracy))\n",
    "print(\"Test Accuracy \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(translate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = parses[110]\n",
    "print(parse.explanation)\n",
    "print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = Cs[0][250]\n",
    "print(element)\n",
    "print(element.text)\n",
    "print(Ys[0][250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parse in parses:\n",
    "    label = parse.function(element)\n",
    "    if label != 0:\n",
    "        print(label)\n",
    "        print(parse.explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,line in enumerate(L_train.T):\n",
    "    if 4 in line:\n",
    "        print(line)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(most_frequent(L_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indexes = []\n",
    "i = 0\n",
    "for right,wrong in zip(Ys[0],Y_p):\n",
    "    if int(right) != wrong:\n",
    "        wrong_indexes.append(i)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wrong_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Ls.pkl\", 'wb') as f:\n",
    "    pickle.dump(Ls, f)\n",
    "    \n",
    "with open(\"Y_p.pkl\", 'wb') as f:\n",
    "    pickle.dump(Y_p, f)\n",
    "    \n",
    "with open(\"data/wrong_indexes.pkl\", 'wb') as f:\n",
    "    pickle.dump(wrong_indexes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:babble] *",
   "language": "python",
   "name": "conda-env-babble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
