{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.utils import log_progress as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_FILE1 = 'data/data.pkl'\n",
    "DATA_FILE2 = 'data/labels.pkl'\n",
    "DATA_FILE3 = 'data/pos_adjectives_list.pkl'\n",
    "DATA_FILE4 = 'data/neu_adjectives_list.pkl'\n",
    "DATA_FILE5 = 'data/neg_adjectives_list.pkl'\n",
    "\n",
    "with open(DATA_FILE1, 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "    \n",
    "with open(DATA_FILE2, 'rb') as f:\n",
    "    stars = pickle.load(f)\n",
    "\n",
    "with open(DATA_FILE3, 'rb') as f:\n",
    "    pos_adjectives_list = pickle.load(f)\n",
    "    \n",
    "with open(DATA_FILE4, 'rb') as f:\n",
    "    neu_adjectives_list = pickle.load(f)\n",
    "\n",
    "with open(DATA_FILE5, 'rb') as f:\n",
    "    neg_adjectives_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_adjectives_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar construction complete.\n"
     ]
    }
   ],
   "source": [
    "from babble.babbler import BabbleStream\n",
    "\n",
    "babbler = BabbleStream(reviews,stars,balanced=True, shuffled=True, seed=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babbler.semparser.grammar.lexical_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelationMention(doc_id=1174: entities=(\"pizza\"(9:14), \"caesar\"(20:26), \"salad\"(27:32), \"service\"(73:80), \"good\"(85:89), \"got\"(97:100))\n",
      "mediocre pizza, bad caesar salad, and high prices. on the positive side, service was good and we got our order very quickly.\n",
      "[(9, 14), (20, 26), (27, 32), (73, 80), (85, 89), (97, 100)]\n"
     ]
    }
   ],
   "source": [
    "from babble.utils import display_candidate\n",
    "\n",
    "candidate = babbler.next()\n",
    "print(candidate)\n",
    "print(candidate.text)\n",
    "print(candidate.entity_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(candidate.entities[0]))\n",
    "print(candidate.entities)\n",
    "print(candidate.entities.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(candidate,adjective):\n",
    "    for entity in candidate.entities:\n",
    "        # qui controllo se gli aggettvi sono vicini alle entità...da capire bene come fare\n",
    "        print(entity.entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(candidate,'fsdfsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "praticamente posso fare cosi: per ogni entità da X a Q, verifico se ci sono aggettivi appena prima o appena dopo(\n",
    "da capire se può creare problemi\") e creo in modo automatico la explanation.\n",
    "Forse è il caso di provare prima con il solo check dell'aggettivo appena prima\"\n",
    "'''\n",
    "from babble import Explanation\n",
    "explanation = Explanation(\n",
    "        name='LF_1',\n",
    "        label=1,\n",
    "        condition='the word \"mediocre\" is before X or the word \"bad\" is before Y or the word \"good\" is after T',\n",
    "        candidate=candidate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: LF_1_4\n",
      "Parse: return 1 if ('mediocre'.in(text(greater than 0 word(s) to the left of X)) or ('bad'.(= text(Y)) or 'good'.(= text(T)))) else 0\n"
     ]
    }
   ],
   "source": [
    "babbler.view_parse(parses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parses[0].semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "/ |#                                                  | 0 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "All 1 explanations are already linked to candidates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |   #                                               | 0 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 explanation(s) out of 1 were parseable.\n",
      "10 parse(s) generated from 1 explanation(s).\n",
      "10 parse(s) remain (0 parse(s) removed by DuplicateSemanticsFilter).\n",
      "8 parse(s) remain (2 parse(s) removed by ConsistencyFilter).\n",
      "Applying labeling functions to investigate labeling signature.\n",
      "[========================================] 100%\n",
      "\n",
      "8 parse(s) remain (0 parse(s) removed by UniformSignatureFilter: (0 None, 0 All)).\n",
      "4 parse(s) remain (4 parse(s) removed by DuplicateSignatureFilter).\n",
      "1 parse(s) remain (3 parse(s) removed by LowestCoverageFilter).\n"
     ]
    }
   ],
   "source": [
    "parses, filtered = babbler.apply(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_condition(words):\n",
    "    condition = 'the word '\n",
    "    for word in words:\n",
    "        condition = condition + '\"'+ word + '\" or '\n",
    "    return condition + 'are in the sentence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "print('spaCy Version: %s' % (spacy.__version__))\n",
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babble import Explanation\n",
    "\n",
    "final_parses = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "for element,label,selected_words in (zip(lp.log_progress(reviews[0]),stars[0],tokens_list)):\n",
    "    doc = spacy_nlp(element.text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop and not token.pos_  in ('PUNCT', 'NUM', 'SYM')]\n",
    "        \n",
    "    print(selected_words)\n",
    "    \n",
    "    explanation = Explanation(\n",
    "        name='LF_' + str(index),\n",
    "        label=int(label),\n",
    "        condition=create_condition(selected_words),\n",
    "        candidate=element\n",
    "    )\n",
    "    parses, filtered = babbler.apply(explanation)\n",
    "    babbler.commit()\n",
    "    \n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import lf_summary\n",
    "\n",
    "Ls = [babbler.get_label_matrix(split) for split in [0,1,2]]\n",
    "lf_names = [lf.__name__ for lf in babbler.get_lfs()]\n",
    "lf_summary(Ls[1], stars[1], lf_names=lf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babble.utils import ExplanationIO\n",
    "\n",
    "explanations = babbler.get_explanations()\n",
    "\n",
    "FILE = \"my_explanations.tsv\"\n",
    "exp_io = ExplanationIO()\n",
    "exp_io.write(explanations, FILE)\n",
    "explanations = exp_io.read(FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:babble] *",
   "language": "python",
   "name": "conda-env-babble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
