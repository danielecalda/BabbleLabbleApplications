{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_FILE1 = 'data/data.pkl'\n",
    "DATA_FILE2 = 'data/labels.pkl'\n",
    "DATA_FILE3 = 'data/pos_adjectives_list.pkl'\n",
    "DATA_FILE4 = 'data/neu_adjectives_list.pkl'\n",
    "DATA_FILE5 = 'data/neg_adjectives_list.pkl'\n",
    "DATA_FILE6 = 'data/nouns_list.pkl'\n",
    "\n",
    "with open(DATA_FILE1, 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "    \n",
    "with open(DATA_FILE2, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "'''\n",
    "with open(DATA_FILE3, 'rb') as f:\n",
    "    pos_adjectives_list = pickle.load(f)\n",
    "    \n",
    "with open(DATA_FILE4, 'rb') as f:\n",
    "    neu_adjectives_list = pickle.load(f)\n",
    "\n",
    "with open(DATA_FILE5, 'rb') as f:\n",
    "    neg_adjectives_list = pickle.load(f)\n",
    "''' \n",
    "with open(DATA_FILE6, 'rb') as f:\n",
    "    nouns_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_names = nouns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar construction complete.\n"
     ]
    }
   ],
   "source": [
    "from babble.babbler import BabbleStream\n",
    "\n",
    "babbler = BabbleStream(reviews,labels,entity_names=entity_names,balanced=True, shuffled=True, seed=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_words_before(quantity,sentence,entity):\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence)\n",
    "    words = sentence.split()\n",
    "    if entity in words:\n",
    "        index = words.index(entity)\n",
    "        before = index - min(index, quantity)\n",
    "        return ' '.join(map(str, words[before:index])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_words_after(quantity,sentence,entity):\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence)\n",
    "    words = sentence.split()\n",
    "    if entity in words:\n",
    "        index = words.index(entity) +1\n",
    "        after = index + min(index, quantity)\n",
    "        return ' '.join(map(str, words[index:after]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adjectives_before(sentence,entity):\n",
    "    words = get_words_before(sentence,entity)\n",
    "    if words == None:\n",
    "        return None\n",
    "    else:\n",
    "        for word in words:\n",
    "            if word in pos_adjectives_list:\n",
    "                return 'positive'\n",
    "            elif word in neu_adjectives_list:\n",
    "                return 'neutral'\n",
    "            elif word in neg_adjectives_list:\n",
    "                return 'negative'\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adjectives_before_pos(sentence,entity):\n",
    "    words = get_words_before(2,sentence,entity)\n",
    "    if words == None or len(words.split(\" \")) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        spacy_nlp = spacy.load('en_core_web_sm')\n",
    "        doc = spacy_nlp(words)\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'ADJ':\n",
    "                return token.text\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adjectives_after_verb(sentence,entity):\n",
    "    words = get_words_after(3,sentence,entity)\n",
    "    if words == None or len(words.split(\" \")) < 3:\n",
    "        return None\n",
    "    else:\n",
    "        spacy_nlp = spacy.load('en_core_web_sm')\n",
    "        doc = spacy_nlp(words)\n",
    "        if doc[0].pos_ == 'VERB' and (doc[1].pos_ == 'ADJ' or doc[2].pos_ == 'ADJ'):\n",
    "            return doc[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Version: 2.1.8\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "print('spaCy Version: %s' % (spacy.__version__))\n",
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- |                                     #             | 5 Elapsed Time: 0:00:06"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-4f33b5607550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#        print(entity.entity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0madjectives_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_adjectives_before_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madjectives_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             explanation = Explanation(\n",
      "\u001b[0;32m<ipython-input-173-4662f798e59a>\u001b[0m in \u001b[0;36mcheck_adjectives_before_pos\u001b[0;34m(sentence, entity)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mspacy_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# installed as package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m\"\"\"Load a model from an installed package.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/en_core_web_sm/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, **overrides)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude, disable)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/babble/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    821\u001b[0m         ) and _fix_pretrained_vectors_name(self)\n\u001b[1;32m    822\u001b[0m         deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from babble import Explanation\n",
    "\n",
    "explanations = []\n",
    "index = 1\n",
    "\n",
    "for candidate,label in progressbar.progressbar(zip(reviews[0],labels[0])):\n",
    "#    print(candidate.text)\n",
    "    for entity in candidate.entities:\n",
    "#        print(entity.entity)\n",
    "        adjectives_value = check_adjectives_before_pos(candidate.text,entity.entity)\n",
    "        if adjectives_value != None:\n",
    "            explanation = Explanation(\n",
    "            name='LF_' + str(index),\n",
    "            label=label,\n",
    "            condition='the word \"' + adjectives_value + '\" is left of the word \"' + entity.entity + '\"', \n",
    "            )\n",
    "            explanations.append(explanation)\n",
    "            index = index + 1\n",
    "#            print(str(explanation).upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Explanation(LF_1: 1, \"the word \"total\" is left of the word \"bill\"\"), Explanation(LF_2: 1, \"the word \"horrible\" is left of the word \"service\"\"), Explanation(LF_3: 1, \"the word \"awful\" is left of the word \"place\"\"), Explanation(LF_4: 1, \"the word \"awful\" is left of the word \"staff\"\"), Explanation(LF_5: 1, \"the word \"other\" is left of the word \"hand\"\"), Explanation(LF_6: 1, \"the word \"odd\" is left of the word \"mix\"\"), Explanation(LF_7: 1, \"the word \"great\" is left of the word \"space\"\"), Explanation(LF_8: 1, \"the word \"napa\" is left of the word \"guy\"\"), Explanation(LF_9: 1, \"the word \"disappointed\" is left of the word \"freezer\"\"), Explanation(LF_10: 1, \"the word \"strawberry\" is left of the word \"cream\"\")]\n"
     ]
    }
   ],
   "source": [
    "print(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(translate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 3 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 0 unique target candidate ids from 10 explanations.\n",
      "No candidate hashes were provided. Skipping linking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |    #                                              | 9 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 explanation(s) out of 10 were parseable.\n",
      "10 parse(s) generated from 10 explanation(s).\n",
      "10 parse(s) remain (0 parse(s) removed by DuplicateSemanticsFilter).\n",
      "Note: 10 LFs did not have candidates and therefore could not be filtered.\n",
      "10 parse(s) remain (0 parse(s) removed by ConsistencyFilter).\n",
      "Applying labeling functions to investigate labeling signature.\n",
      "[========================================] 100%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([Parse(LF_1_0),\n",
       "  Parse(LF_2_0),\n",
       "  Parse(LF_3_0),\n",
       "  Parse(LF_4_0),\n",
       "  Parse(LF_5_0),\n",
       "  Parse(LF_6_0),\n",
       "  Parse(LF_7_0),\n",
       "  Parse(LF_8_0),\n",
       "  Parse(LF_9_0),\n",
       "  Parse(LF_10_0)],\n",
       " {'DuplicateSemanticsFilter': [],\n",
       "  'ConsistencyFilter': [],\n",
       "  'UnparseableExplanations': []})"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babbler.apply(explanations,split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                             | 9 Elapsed Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "parses = babbler.semparser.parse(explanations, return_parses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'bill')), ('.string', 'total'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'service')), ('.string', 'horrible'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'place')), ('.string', 'awful'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'staff')), ('.string', 'awful'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'hand')), ('.string', 'other'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'mix')), ('.string', 'odd'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'space')), ('.string', 'great'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'guy')), ('.string', 'napa'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'freezer')), ('.string', 'disappointed'))))\n",
      "('.root', ('.label', ('.int', 1), ('.call', ('.eq', ('.string', 'cream')), ('.string', 'strawberry'))))\n"
     ]
    }
   ],
   "source": [
    "for parse in parses:\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = babbler.semparser.translate(parses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelationMention(doc_id=35: entities=(\"pizza\"(13:18), \"recommend\"(83:92))\n",
      "flies on the pizza that was sitting out there.  ew.  very disgusting.  i would not recommend it ... very unsanitary!\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0][34])\n",
    "print(reviews[0][34].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Explanation(LF_2: 1, \"the word \"horrible\" is left of service\")"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[1].explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lambda int_: ['food', 'place', 'service', 'time', 'staff', 'chicken', 'restaurant', 'price', 'breakfast', 'pizza', 'location', 'menu', 'atmosphere', 'coffee', 'quality', 'thing', 'customer', 'bar', 'hour', 'job', 'night', 'lot', 'home', 'order', 'store', 'experience', 'salad', 'meat', 'beef', 'lunch', 'family', 'ice', 'table', 'way', 'soup', 'cheese', 'area', 'dinner', 'burger', 'spot', 'cream', 'drink', 'shop', 'flavor', 'bit', 'car', 'rice', 'house', 'strip', 'owner', 'group', 'vegas', 'fan', 'room', 'money', 'style', 'work', 'wait', 'tea', 'shrimp', 'review', 'visit', 'seafood', 'plate', 'star', 'selection', 'decor', 'hotel', 'fish', 'business', 'line', 'airport', 'massage', 'buffet', 'sandwich', 'friend', 'point', 'drive', 'sauce', 'taste', 'crab', 'station', 'beer', 'pool', 'bread', 'morning', 'reason', 'waitress', 'steak', 'party', 'gas', 'gravy', 'birthday', 'cash', 'couple', 'patio', 'seating', 'care', 'vibe', 'bill', 'water', 'guy', 'item', 'meal', 'counter', 'life', 'server', 'phone', 'toast', 'crust', 'parking', 'try', 'reservation', 'brunch', 'texture', 'chocolate', 'favorite', 'deal', 'variety', 'ambiance', 'dip', 'idea', 'mix', 'oil', 'credit', 'company', 'bowl', 'street', 'change', 'management', 'country', 'valley', 'concept', 'haircut', 'pm', 'end', 'section', 'number', 'hair', 'pasta', 'pricing', 'meh', 'phoenix', 'wine', 'portion', 'mall', 'movie', 'rest', 'card', 'tonight', 'cost', 'pittsburgh', 'trip', 'neighborhood', 'size', 'rush', 'bomb', 'art', 'pork', 'design', 'bakery', 'environment', 'slice', 'ahi', 'margarita', 'town', 'curry', 'salon', 'venue', 'downtown', 'min', 'wife', 'hand', 'space', 'yelp', 'office', 'response', 'appointment', 'flight', 'cut', 'dish', 'kitchen', 'gym', 'franchise', 'crap', 'self', 'onion', 'case', 'stomach', 'trash', 'team', 'lady', 'club', 'king', 'hat', 'man', 'joint', 'waste', 'gf', 'foot', 'wash', 'delivery', 'husband', 'person', 'friday', 'guest', 'fruit', 'sum', 'pot', 'mouth', 'music', 'doughy', 'dessert', 'corn', 'sugar', 'hype', 'machine', 'plenty', 'fun', 'desert', 'alcohol', 'lol', 'bbq', 'steel', 'gift', 'cuisine', 'grocery', 'value', 'picture', 'mexican', 'sea', 'technician', 'lamb', 'class', 'thai', 'egg', 'pricey', 'son', 'dining', 'state', 'bartender', 'par', 'problem', 'half', 'run', 'mill', 'mess', 'suggestion', 'quantity', 'manager', 'head', 'rip', 'luck', 'nachos', 'walmart', 'shower', 'sun', 'skirt', 'mex', 'dash', 'interior', 'refund', 'temperature', 'word', 'need', 'game', 'pain', 'security', 'pedi', 'plague', 'contract', 'etiquette', 'waiter', 'bacon', 'product', 'avoid', 'register', 'ordering', 'process', 'calamari', 'batter', 'rock', 'chance', 'cleaning', 'employee', 'afternoon', 'tequila', 'smell', 'cook', 'dim', 'chick', 'wifi', 'adult', 'burrito', 'cardboard', 'heart', 'combo', 'chip', 'dollar', 'charlotte', 'shame', 'floor', 'miami', 'shopping', 'italian', 'layout', 'marathon', 'cone', 'month', 'pinch', 'theatre', 'checkout', 'bird', 'poop', 'treat', 'brisket', 'favor', 'masala', 'wrap', 'tzatziki', 'cucumber', 'day', 'parm', 'bummer', 'scoop', 'tempe', 'latte', 'lobster', 'scottsdale', 'voice', 'message', 'key', 'fare', 'computer', 'pepperoni', 'chinese', 'croissant', 'smile', 'tasting', 'cleveland', 'shuttle', 'facility', 'stay', 'ball', 'glass', 'carl', 'fix', 'tuna', 'roll', 'bosa', 'rotisserie', 'specialty', 'stone', 'quesadilla', 'school', 'matcha', 'daughter', 'cake', 'dog', 'jjajeongmyeon', 'flavour', 'salt', 'middle', 'sushi', 'fusion', 'potato', 'noodle', 'salmon', 'spicy', 'boo', 'broth', 'level', 'greek', 'mary', 'juice', 'list', 'appetizer', 'combination', 'pad', 'bonus', 'snow', 'rib', 'tip', 'pub', 'protein', 'laser', 'tattoo', 'difference', 'city', 'pie', 'kid', 'blast', 'falafel', 'hummus', 'pumpkin', 'help', 'branch', 'chef', 'earth', 'wonton', 'tech', 'health', 'shortbread', 'client', 'bean', 'vegan', 'recommend', 'dr', 'desk', 'omelette', 'ashley', 'personality', 'nerve', 'hospital', 'ers', 'filter', 'freezer', 'rebel', 'debit', 'lake', 'finance', 'charge', 'tendency', 'email', 'ugh', 'california', 'chipotle', 'yonge', 'college', 'cobb', 'button', 'bell', 'receiver', 'amazon', 'advance', 'rate', 'airline', 'overprice', 'mechanic', 'bike', 'dale', 'kieffer', 'dealer', 'chair', 'safety', 'cockroach', 'ghetto', 'ceiling', 'sauna', 'oph', 'minneapolis', 'chicago', 'seattle', 'frybread', 'substance', 'ground', 'site', 'rent', 'quilt', 'girl', 'alex', 'lack', 'professionalism', 'courtesy', 'remodel', 'popcorn', 'oven', 'omg', 'father', 'pho', 'base', 'convenience', 'poster', 'child', 'procurement', 'subject', 'forum', 'bland', 'grease', 'indigestion', 'sub', 'contact', 'lawyer', 'w', 'constance', 'eric', 'mvp', 'record', 'fault', 'talker', 'forgot', 'praffin', 'wax', 'eye', 'salesman', 'equipment', 'fail', 'cringe', 'song', 'lord', 'public', 'godzilla', 'container', 'bun', 'blame', 'booth', 'wanna', 'celiac', 'contamination', 'reaction', 'estimate', 'amy', 'gate', 'cup', 'notice', 'total', 'pride', 'arcade', 'excuse', 'budget', 'tracking', 'package', 'daytime', 'fuck', 'bitch', 'tom', 'yum', 'spice', 'stir', 'fry', 'odor', 'mule', 'advertisement', 'woman', 'industry', 'addition', 'screen', 'guarantee', 'minute', 'book', 'tude', 'mucky', 'greenery', 'botany', 'stroll', 'shelf', 'fly', 'driving', 'ave', 'ambulance', 'mistake', 'window', 'mile', 'clearance', 'compare', 'spoon', 'bachannal', 'comparison', 'attitude', 'pickle', 'river', 'cappuccino', 'ceasar', 'poisoning', 'tongue', 'throat', 'gratuity', 'walk', 'dundas', 'representation', 'brand', 'reputation', 'story', 'course', 'fil', 'urgency', 'inside', 'nught', 'pudding', 'week', 'question', 'plastic', 'jen', 'disaster', 'bert', 'ernie', 'fort', 'apache', 'yummy', 'mgm', 'layover', 'grime', 'hip', 'valet', 'allure', 'montrose', 'chain', 'upside', 'aloft', 'beachwood', 'activity', 'improvement', 'guac', 'asian', 'channel', 'b', 'cue', 'road', 'mash', 'cleanliness', 'radio', 'eagle', 'mildew', 'hill', 'standard', 'platter', 'tv', 'wall', 'noisy', 'mood', 'steakhouse', 'garbage', 'summertime', 'strapped', 'meet', 'durango', 'hood', 'windshield', 'sense', 'dairy', 'queen', 'abondigas', 'risk', 'hash', 'extent', 'ihop', 'dal', 'daal', 'makahni', 'jamun', 'mis', 'check', 'improve', 'customization', 'shit', 'wedding', 'negative', 'chili', 'ethnicity', 'set', 'paste', 'boyfriend', 'seabass', 'fortune', 'spin', 'tender', 'mayo', 'thinking', 'cr', 'chief', 'mother', 'brother', 'girlfriend', 'sangria', 'alla', 'gigi', 'superstition', 'noise', 'smh', 'calamity', 'evening', 'post', 'jasmine', 'mac', 'kobe', 'good', 'complaint', 'human', 'mailbox', 'nieghborhood', 'towner', 'version', 'view', 'tower', 'casino', 'cajun', 'gal', 'fyi', 'arm', 'rise', 'closeby', 'discount', 'panda', 'serve', 'news', 'bf', 'feel', 'broccoli', 'palermo', 'referral', 'brussel', 'disappointment', 'spring', 'cinnamon', 'exercise', 'groupon', 'lb', 'lane', 'pc', 'bucket', 'wth', 'imnot', 'heat', 'jacket', 'scarf', 'collection', 'tile', 'district', 'relative', 'bathroom', 'yogurt', 'heather', 'tortilla', 'squeeze', 'lime', 'pico', 'allé', 'à', 'ottavio', 'les', 'capiccole', 'sur', 'étaient', 'prix', 'ils', 'changés', 'recette', 'jr', 'figure', 'nope', 'denny', 'wheat', 'bang', 'buck', 'ambience', 'staffing', 'atleast', 'donut', 'boston', 'verdict', 'shave', 'start', 'latino', 'establishment', 'english', 'soda', 'freeway', 'replacement', 'awkwardness', 'boulevard', 'hurry', 'jelly', 'popsicle', 'sticker', 'world', 'cookout', 'craft', 'tourist', 'trap', 'mediterranean', 'quinoa', 'garden', 'gourmet', 'depot', 'goal', 'bag', 'website', 'choice', 'storage', 'dough', 'outside', 'pat', 'zoey', 'jade', 'investment', 'teriaki', 'ppl', 'snack', 'gall', 'pepper', 'dentist', 'keeper', 'humus', 'term', 'taker', 'cafe', 'melt', 'touch', 'stock', 'rainbow', 'mandu', 'acknowledgement', 'indifference', 'event', 'concentrate', 'casio', 'kenzo', 'coke', 'sale', 'china', 'portofino', 'dinning', 'beach', 'ravioli', 'sign', 'mom', 'york', 'papaya', 'melancholy', 'adventure', 'bagel', 'meatloaf', 'quaint', 'caviar', 'tartare', 'thurnderbird', 'avenue', 'effort', 'chimichanga', 'queso', 'calzone', 'pita', 'jungle', 'flatbread', 'gazpacho', 'cashier', 'grub', 'chowder', 'foam', 'salsa', 'charro', 'omlete', 'raisin', 'cookie', 'parathas', 'expectation', 'cum', 'nee', 'venetian', 'suite', 'remainder', 'rendition', 'responsiveness', 'maintenance', 'access', 'fi', 'coast', 'resturant', 'croed', 'neighbourhood', 'sound', 'theater', 'taxi', 'chaos', 'shell', 'celent', 'arugula', 'cheddar', 'korean', 'craving', 'bubbling', 'gam', 'comfort', 'coating', 'eatery', 'setting', 'shwarma', 'volume', 'light', 'ridge', 'triangle', 'magazine', 'walnut', 'pointe', 'café', 'benedict', 'wynn', 'sunrise', 'mongolian', 'easter', 'doughnut', 'sucker', 'valhrona', 'produce', 'maple', 'aftertaste', 'buffalo', 'soldier', 'alabama', 'gem', 'break', 'yarn', 'asparagus', 'ham', 'octopus', 'butcher', 'plating', 'fire', 'type', 'dosa', 'range', 'downside', 'ac', 'cooler', 'instagram', 'pic', 'herbst', 'sarra', 'baristas', 'ability', 'omni', 'spa', 'alot', 'training', 'thrn', 'tilapia', 'upcharge', 'pace', 'slim', 'texas', 'planet', 'pettuccine', 'veal', 'piccata', 'resto', 'west', 'transformation', 'residence', 'inspection', 'roof', 'ahwahtukee', 'find', 'satay', 'roti', 'bff', 'tsoynamis', 'belly', 'ny', 'bourbon', 'butter', 'jam', 'tanning', 'checkin', 'relaxation', 'vitamin', 'd', 'kale', 'farm', 'galley', 'boy', 'milkshake', 'balance', 'chill', 'laura', 'football', 'bloodys', 'loco', 'watering', 'hole', 'bubble', 'tad', 'champagne', 'ms', 'crunch', 'oooh', 'momma', 'everytime', 'baja', 'professional', 'concern', 'law', 'schweenie', 'christina', 'splitting', 'beginning', 'seat', 'britney', 'jlo', 'sultry', 'energy', 'love', 'gardein', 'broccolini', 'tanner', 'iphone', 'aggravation', 'animal', 'member', 'follow', 'sympathy'][int_ - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lambda c: c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y(reviews[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-012d7fcf0a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candidate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "parses[1].function['candidate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-a3f90d87cf8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlabel_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_label_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/parsing/grammar.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(candidate)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mLF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemantics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aliases'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'candidate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/core/core_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    111\u001b[0m ops = {\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;34m'.root'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;34m'.label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# primitives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/core/core_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;34m'.root'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;34m'.label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;31m# primitives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;34m'.bool'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/core/core_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m'.map'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfunc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcxy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# call a 'hungry' evaluated function on one or more arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;34m'.call'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# apply a list of hungry functions to an element, then call 'any' or 'all' to convert to boolean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;34m'.composite_and'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcxy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/core/core_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(cy)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;34m'.gt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;34m'.in'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;34m'.contains'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;34m'.count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/text/text_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;34m'.within'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_within_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;34m'.between'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_between_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0;34m'.sentence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_sentence_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candidate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;34m'.extract_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mphr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;34m'.filter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mphr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phrase_filter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/text/text_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(cx)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m'.arg_to_string'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;34m'.cid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entity_attrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'entity_cids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# take the first token's CID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;34m'.left'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_left_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;34m'.right'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_right_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/text/text_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m'.arg_to_string'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;34m'.cid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_entity_attrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'entity_cids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# take the first token's CID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;34m'.left'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_left_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;34m'.right'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'helpers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_right_phrase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/babble/babble/core/core_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;34m'.all_equal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mlist_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmylist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;34m'.arg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candidate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     }\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "lfs = [parse for parse in parses]\n",
    "dense_label_matrix = np.zeros((len(reviews[0]), len(lfs)))\n",
    "\n",
    "for i,c in enumerate(reviews[0]):\n",
    "    print(parses[1].function(c))\n",
    "pb.close()\n",
    "label_matrix = csr_matrix(dense_label_matrix)\n",
    "return label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"X\", \"Y\", \"Z\"].Find(item => item.name == \"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lambda x: lambda c: c['candidate'][x(c) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = y(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda>.<locals>.<lambda> at 0x7f9796d03510>\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = reviews[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityMention(doc_id=1: 'total'(0:5)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lll(2,reviews[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 parse(s) from 10 explanations to set. (Total # parses = 10)\n",
      "\n",
      "Applying labeling functions to split 1\n",
      "[========================================] 100%\n",
      "\n",
      "Added 0 labels to split 1: L.nnz = 0, L.shape = (361, 10).\n",
      "Applying labeling functions to split 2\n",
      "[========================================] 100%\n",
      "\n",
      "Added 0 labels to split 2: L.nnz = 0, L.shape = (361, 10).\n"
     ]
    }
   ],
   "source": [
    "babbler.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.analysis import lf_summary\n",
    "\n",
    "Ls = [babbler.get_label_matrix(split) for split in [0,1,2]]\n",
    "lf_names = [lf.__name__ for lf in babbler.get_lfs()]\n",
    "lf_summary(Ls[1], labels[1], lf_names=lf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babble.utils import ExplanationIO2\n",
    "\n",
    "FILE = \"data/my_explanations.tsv\"\n",
    "exp_io = ExplanationIO2()\n",
    "exp_io.write(explanations, FILE)\n",
    "explanations = exp_io.read(FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:babble] *",
   "language": "python",
   "name": "conda-env-babble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
