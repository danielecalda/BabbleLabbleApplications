{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from src.PipelineReviewFullRandom.utils import most_frequent, calculate_number_wrong, \\\n",
    "    create_tokens_from_choiced_explanations, percentage, high_coverage_elements, high_correct_elements, intersection\n",
    "\n",
    "DATA_FILE1 = 'data/data.pkl'\n",
    "DATA_FILE2 = 'data/labels.pkl'\n",
    "\n",
    "\n",
    "def analyze(ls, parses):\n",
    "\n",
    "    DATA_FILE5 = 'data/predicted_training_labels.pkl'\n",
    "    DATA_FILE7 = 'data/summary.txt'\n",
    "    DATA_FILE8 = 'data/predicted_test_labels.pkl'\n",
    "\n",
    "    with open(DATA_FILE2, 'rb') as f:\n",
    "        Ys = pickle.load(f)\n",
    "\n",
    "    L_train = ls[0].toarray()\n",
    "    L_test = ls[2].toarray()\n",
    "\n",
    "    predicted_training_labels = []\n",
    "    predicted_test_labels = []\n",
    "\n",
    "    for line in L_train:\n",
    "        predicted_training_labels.append(most_frequent(line))\n",
    "\n",
    "    for line in L_test:\n",
    "        predicted_test_labels.append(most_frequent(line))\n",
    "\n",
    "    with open(DATA_FILE5, 'wb') as f:\n",
    "        pickle.dump(predicted_training_labels, f)\n",
    "\n",
    "    with open(DATA_FILE8, 'wb') as f:\n",
    "        pickle.dump(predicted_test_labels, f)\n",
    "\n",
    "    len_wrong_train = calculate_number_wrong(Ys[0], predicted_training_labels)\n",
    "\n",
    "    len_wrong_test = calculate_number_wrong(Ys[2], predicted_test_labels)\n",
    "\n",
    "    training_accuracy = percentage(len(Ys[0]) - len_wrong_train, len(Ys[0]))\n",
    "\n",
    "    test_accuracy = percentage(len(Ys[2]) - len_wrong_test, len(Ys[2]))\n",
    "\n",
    "    with open(DATA_FILE7, 'a') as f:\n",
    "        f.write(\"Iteration number: \")\n",
    "        f.write('\\n')\n",
    "        f.write(\"Number of wrong in training set: \" + str(len_wrong_train))\n",
    "        f.write('\\n')\n",
    "        f.write(\"Number of wrong in test set: \" + str(len_wrong_test))\n",
    "        f.write('\\n')\n",
    "        f.write(\"Training Accuracy: \" + str(training_accuracy))\n",
    "        f.write('\\n')\n",
    "        f.write(\"Test Accuracy: \" + str(test_accuracy))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "    L_train_transpose = L_train.T\n",
    "\n",
    "    over_percentage = high_coverage_elements(L_train_transpose)\n",
    "    correct_elements, wrong_elements = high_correct_elements(L_train_transpose, Ys)\n",
    "\n",
    "    intersect = intersection(over_percentage, correct_elements)\n",
    "    print(len(intersect))\n",
    "    print(intersect)\n",
    "\n",
    "    new_explanations = []\n",
    "    for index in intersect:\n",
    "        explanation = parses[index].explanation\n",
    "        new_explanations.append(explanation)\n",
    "\n",
    "    wrong_explanations = []\n",
    "    for index in wrong_elements:\n",
    "        wrong_explanation = parses[index].explanation\n",
    "        wrong_explanations.append(wrong_explanation)\n",
    "\n",
    "    print(new_explanations)\n",
    "    print(wrong_explanations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:babble] *",
   "language": "python",
   "name": "conda-env-babble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
